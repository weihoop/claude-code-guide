# ç¼–ç¨‹ä½¿ç”¨ Skills æŒ‡å—

é€šè¿‡ Python å’Œ Node.js SDK åœ¨ä»£ç ä¸­ä½¿ç”¨ Claude Skillsï¼Œå®ç°è‡ªåŠ¨åŒ–å·¥ä½œæµã€‚

## ğŸ“š ç›®å½•

- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [Python SDK](#python-sdk)
- [Node.js SDK](#nodejs-sdk)
- [é«˜çº§ç”¨æ³•](#é«˜çº§ç”¨æ³•)
- [æ‰¹é‡å¤„ç†](#æ‰¹é‡å¤„ç†)
- [é”™è¯¯å¤„ç†](#é”™è¯¯å¤„ç†)
- [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
- [å®æˆ˜æ¡ˆä¾‹](#å®æˆ˜æ¡ˆä¾‹)

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£… SDK

**Python**:
```bash
pip install anthropic
```

**Node.js**:
```bash
npm install @anthropic-ai/sdk
```

### åŸºç¡€ç¤ºä¾‹

**Python**:
```python
import anthropic

client = anthropic.Anthropic(api_key="your-api-key")

response = client.messages.create(
    model="claude-sonnet-4-20250514",
    max_tokens=1024,
    skills=["pdf"],  # åŠ è½½ pdf skill
    messages=[
        {"role": "user", "content": "åˆ†æè¿™ä¸ª PDF æ–‡ä»¶"}
    ]
)

print(response.content[0].text)
```

**Node.js**:
```javascript
import Anthropic from "@anthropic-ai/sdk";

const client = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY,
});

const response = await client.messages.create({
  model: "claude-sonnet-4-20250514",
  max_tokens: 1024,
  skills: ["pdf"],
  messages: [
    { role: "user", content: "åˆ†æè¿™ä¸ª PDF æ–‡ä»¶" }
  ],
});

console.log(response.content[0].text);
```

---

## ğŸ Python SDK

### å®Œæ•´ç¤ºä¾‹

```python
import anthropic
import os
from typing import List, Dict, Any

class SkillClient:
    """å°è£… Anthropic API çš„ Skill å®¢æˆ·ç«¯"""

    def __init__(self, api_key: str = None):
        self.api_key = api_key or os.getenv("ANTHROPIC_API_KEY")
        self.client = anthropic.Anthropic(api_key=self.api_key)

    def use_skill(
        self,
        skill_names: List[str],
        prompt: str,
        model: str = "claude-sonnet-4-20250514",
        max_tokens: int = 4096
    ) -> str:
        """ä½¿ç”¨æŒ‡å®šçš„ Skills å¤„ç†æç¤ºè¯"""
        response = self.client.messages.create(
            model=model,
            max_tokens=max_tokens,
            skills=skill_names,
            messages=[
                {"role": "user", "content": prompt}
            ]
        )
        return response.content[0].text

    def analyze_document(
        self,
        file_path: str,
        skill: str = "pdf"
    ) -> Dict[str, Any]:
        """åˆ†ææ–‡æ¡£å¹¶è¿”å›ç»“æ„åŒ–ç»“æœ"""
        with open(file_path, "rb") as f:
            content = f.read()

        prompt = f"åˆ†æè¿™ä¸ªæ–‡æ¡£å¹¶æå–å…³é”®ä¿¡æ¯ï¼š\n\n{file_path}"

        result = self.use_skill(
            skill_names=[skill],
            prompt=prompt
        )

        return {
            "file_path": file_path,
            "analysis": result,
            "skill_used": skill
        }

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    client = SkillClient()

    # å•ä¸ªæ–‡æ¡£åˆ†æ
    result = client.analyze_document("report.pdf", "pdf")
    print(result["analysis"])

    # ä½¿ç”¨å¤šä¸ª Skills
    result = client.use_skill(
        skill_names=["pdf", "xlsx"],
        prompt="åˆ†æè¿™äº›è´¢åŠ¡æŠ¥è¡¨å¹¶ç”Ÿæˆæ‘˜è¦"
    )
    print(result)
```

### å¼‚æ­¥ç‰ˆæœ¬

```python
import anthropic
import asyncio
from typing import List

class AsyncSkillClient:
    """å¼‚æ­¥ Skill å®¢æˆ·ç«¯"""

    def __init__(self, api_key: str = None):
        self.client = anthropic.AsyncAnthropic(
            api_key=api_key or os.getenv("ANTHROPIC_API_KEY")
        )

    async def use_skill(
        self,
        skill_names: List[str],
        prompt: str
    ) -> str:
        """å¼‚æ­¥ä½¿ç”¨ Skill"""
        response = await self.client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=4096,
            skills=skill_names,
            messages=[{"role": "user", "content": prompt}]
        )
        return response.content[0].text

    async def batch_analyze(
        self,
        prompts: List[str],
        skill: str
    ) -> List[str]:
        """æ‰¹é‡å¼‚æ­¥åˆ†æ"""
        tasks = [
            self.use_skill([skill], prompt)
            for prompt in prompts
        ]
        return await asyncio.gather(*tasks)

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    client = AsyncSkillClient()

    prompts = [
        "åˆ†æ Q1 é”€å”®æ•°æ®",
        "åˆ†æ Q2 é”€å”®æ•°æ®",
        "åˆ†æ Q3 é”€å”®æ•°æ®",
    ]

    results = await client.batch_analyze(prompts, "xlsx")
    for i, result in enumerate(results, 1):
        print(f"Q{i} åˆ†æç»“æœï¼š\n{result}\n")

asyncio.run(main())
```

---

## ğŸŸ¢ Node.js SDK

### å®Œæ•´ç¤ºä¾‹

```javascript
import Anthropic from "@anthropic-ai/sdk";
import fs from "fs/promises";

class SkillClient {
  constructor(apiKey = process.env.ANTHROPIC_API_KEY) {
    this.client = new Anthropic({ apiKey });
  }

  async useSkill(skillNames, prompt, options = {}) {
    const {
      model = "claude-sonnet-4-20250514",
      maxTokens = 4096,
    } = options;

    const response = await this.client.messages.create({
      model,
      max_tokens: maxTokens,
      skills: skillNames,
      messages: [{ role: "user", content: prompt }],
    });

    return response.content[0].text;
  }

  async analyzeDocument(filePath, skill = "pdf") {
    const content = await fs.readFile(filePath);
    const prompt = `åˆ†æè¿™ä¸ªæ–‡æ¡£å¹¶æå–å…³é”®ä¿¡æ¯ï¼š\n\n${filePath}`;

    const analysis = await this.useSkill([skill], prompt);

    return {
      filePath,
      analysis,
      skillUsed: skill,
    };
  }

  async batchAnalyze(prompts, skill) {
    const promises = prompts.map((prompt) =>
      this.useSkill([skill], prompt)
    );
    return await Promise.all(promises);
  }
}

// ä½¿ç”¨ç¤ºä¾‹
const client = new SkillClient();

// å•ä¸ªæ–‡æ¡£åˆ†æ
const result = await client.analyzeDocument("report.pdf", "pdf");
console.log(result.analysis);

// æ‰¹é‡å¤„ç†
const prompts = [
  "åˆ†æ Q1 é”€å”®æ•°æ®",
  "åˆ†æ Q2 é”€å”®æ•°æ®",
  "åˆ†æ Q3 é”€å”®æ•°æ®",
];

const results = await client.batchAnalyze(prompts, "xlsx");
results.forEach((result, i) => {
  console.log(`Q${i + 1} åˆ†æç»“æœï¼š\n${result}\n`);
});
```

### TypeScript ç‰ˆæœ¬

```typescript
import Anthropic from "@anthropic-ai/sdk";
import type { Message } from "@anthropic-ai/sdk/resources";

interface SkillOptions {
  model?: string;
  maxTokens?: number;
}

interface AnalysisResult {
  filePath: string;
  analysis: string;
  skillUsed: string;
}

class SkillClient {
  private client: Anthropic;

  constructor(apiKey: string = process.env.ANTHROPIC_API_KEY!) {
    this.client = new Anthropic({ apiKey });
  }

  async useSkill(
    skillNames: string[],
    prompt: string,
    options: SkillOptions = {}
  ): Promise<string> {
    const {
      model = "claude-sonnet-4-20250514",
      maxTokens = 4096,
    } = options;

    const response: Message = await this.client.messages.create({
      model,
      max_tokens: maxTokens,
      skills: skillNames,
      messages: [{ role: "user", content: prompt }],
    });

    return response.content[0].text;
  }

  async analyzeDocument(
    filePath: string,
    skill: string = "pdf"
  ): Promise<AnalysisResult> {
    const prompt = `åˆ†æè¿™ä¸ªæ–‡æ¡£ï¼š${filePath}`;
    const analysis = await this.useSkill([skill], prompt);

    return {
      filePath,
      analysis,
      skillUsed: skill,
    };
  }
}

// ä½¿ç”¨ç¤ºä¾‹
const client = new SkillClient();
const result = await client.analyzeDocument("report.pdf");
console.log(result.analysis);
```

---

## ğŸš€ é«˜çº§ç”¨æ³•

### 1. æµå¼å“åº”

**Python**:
```python
def stream_analysis(client, skill, prompt):
    """æµå¼æ¥æ”¶åˆ†æç»“æœ"""
    with client.messages.stream(
        model="claude-sonnet-4-20250514",
        max_tokens=4096,
        skills=[skill],
        messages=[{"role": "user", "content": prompt}]
    ) as stream:
        for text in stream.text_stream:
            print(text, end="", flush=True)
        print()  # æ¢è¡Œ

# ä½¿ç”¨
client = anthropic.Anthropic()
stream_analysis(client, "pdf", "åˆ†æè¿™ä¸ª PDF æ–‡ä»¶")
```

**Node.js**:
```javascript
async function streamAnalysis(client, skill, prompt) {
  const stream = await client.messages.stream({
    model: "claude-sonnet-4-20250514",
    max_tokens: 4096,
    skills: [skill],
    messages: [{ role: "user", content: prompt }],
  });

  for await (const chunk of stream) {
    if (chunk.type === "content_block_delta") {
      process.stdout.write(chunk.delta.text);
    }
  }
  console.log(); // æ¢è¡Œ
}

// ä½¿ç”¨
await streamAnalysis(client, "pdf", "åˆ†æè¿™ä¸ª PDF æ–‡ä»¶");
```

### 2. ä¸Šä¸‹æ–‡å¯¹è¯

```python
def conversation_with_skills(client, skills):
    """å¸¦ Skills çš„å¤šè½®å¯¹è¯"""
    messages = []

    while True:
        user_input = input("ä½ : ")
        if user_input.lower() in ["é€€å‡º", "exit", "quit"]:
            break

        messages.append({"role": "user", "content": user_input})

        response = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=4096,
            skills=skills,
            messages=messages
        )

        assistant_message = response.content[0].text
        messages.append({"role": "assistant", "content": assistant_message})

        print(f"Claude: {assistant_message}\n")

# ä½¿ç”¨
client = anthropic.Anthropic()
conversation_with_skills(client, ["pdf", "xlsx"])
```

### 3. æ¡ä»¶åŠ è½½ Skills

```python
def smart_skill_selection(file_path: str) -> List[str]:
    """æ ¹æ®æ–‡ä»¶ç±»å‹æ™ºèƒ½é€‰æ‹© Skill"""
    ext = file_path.lower().split(".")[-1]

    skill_map = {
        "pdf": ["pdf"],
        "docx": ["docx"],
        "doc": ["docx"],
        "xlsx": ["xlsx"],
        "xls": ["xlsx"],
        "pptx": ["pptx"],
        "csv": ["xlsx"],  # CSV ä¹Ÿå¯ä»¥ç”¨ xlsx skill
    }

    return skill_map.get(ext, [])

def analyze_file(client, file_path: str):
    """æ™ºèƒ½åˆ†ææ–‡ä»¶"""
    skills = smart_skill_selection(file_path)

    if not skills:
        print(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼š{file_path}")
        return

    prompt = f"åˆ†æè¿™ä¸ªæ–‡ä»¶ï¼š{file_path}"
    result = client.messages.create(
        model="claude-sonnet-4-20250514",
        max_tokens=4096,
        skills=skills,
        messages=[{"role": "user", "content": prompt}]
    )

    return result.content[0].text

# ä½¿ç”¨
client = anthropic.Anthropic()
result = analyze_file(client, "report.pdf")
print(result)
```

---

## ğŸ“¦ æ‰¹é‡å¤„ç†

### Python æ‰¹é‡å¤„ç†å™¨

```python
import concurrent.futures
from pathlib import Path
from typing import List, Dict

class BatchProcessor:
    """æ‰¹é‡æ–‡æ¡£å¤„ç†å™¨"""

    def __init__(self, client: anthropic.Anthropic):
        self.client = client

    def process_directory(
        self,
        directory: str,
        pattern: str = "*.pdf",
        max_workers: int = 5
    ) -> List[Dict]:
        """æ‰¹é‡å¤„ç†ç›®å½•ä¸­çš„æ–‡ä»¶"""
        files = list(Path(directory).glob(pattern))
        results = []

        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {
                executor.submit(self.process_file, str(file)): file
                for file in files
            }

            for future in concurrent.futures.as_completed(futures):
                file = futures[future]
                try:
                    result = future.result()
                    results.append(result)
                    print(f"âœ… å®Œæˆï¼š{file.name}")
                except Exception as e:
                    print(f"âŒ å¤±è´¥ï¼š{file.name} - {e}")

        return results

    def process_file(self, file_path: str) -> Dict:
        """å¤„ç†å•ä¸ªæ–‡ä»¶"""
        skills = smart_skill_selection(file_path)

        response = self.client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=4096,
            skills=skills,
            messages=[{
                "role": "user",
                "content": f"åˆ†ææ–‡ä»¶ï¼š{file_path}"
            }]
        )

        return {
            "file_path": file_path,
            "analysis": response.content[0].text,
            "skills_used": skills
        }

# ä½¿ç”¨
client = anthropic.Anthropic()
processor = BatchProcessor(client)

results = processor.process_directory(
    directory="./documents",
    pattern="*.pdf",
    max_workers=3
)

# ä¿å­˜ç»“æœ
for result in results:
    output_file = f"{result['file_path']}_analysis.txt"
    with open(output_file, "w") as f:
        f.write(result["analysis"])
```

---

## âš ï¸ é”™è¯¯å¤„ç†

### å®Œæ•´çš„é”™è¯¯å¤„ç†

```python
from anthropic import APIError, APIConnectionError, RateLimitError
import time

def robust_skill_call(
    client,
    skills: List[str],
    prompt: str,
    max_retries: int = 3
) -> str:
    """å¸¦é‡è¯•æœºåˆ¶çš„ Skill è°ƒç”¨"""
    for attempt in range(max_retries):
        try:
            response = client.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=4096,
                skills=skills,
                messages=[{"role": "user", "content": prompt}]
            )
            return response.content[0].text

        except RateLimitError as e:
            if attempt < max_retries - 1:
                wait_time = 2 ** attempt  # æŒ‡æ•°é€€é¿
                print(f"é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                time.sleep(wait_time)
            else:
                raise

        except APIConnectionError as e:
            if attempt < max_retries - 1:
                print(f"è¿æ¥é”™è¯¯ï¼Œé‡è¯• {attempt + 1}/{max_retries}...")
                time.sleep(1)
            else:
                raise

        except APIError as e:
            print(f"API é”™è¯¯ï¼š{e}")
            raise

        except Exception as e:
            print(f"æœªçŸ¥é”™è¯¯ï¼š{e}")
            raise

# ä½¿ç”¨
client = anthropic.Anthropic()
try:
    result = robust_skill_call(
        client,
        ["pdf"],
        "åˆ†æè¿™ä¸ª PDF æ–‡ä»¶"
    )
    print(result)
except Exception as e:
    print(f"æœ€ç»ˆå¤±è´¥ï¼š{e}")
```

---

## âš¡ æ€§èƒ½ä¼˜åŒ–

### 1. ç¼“å­˜ç­–ç•¥

```python
from functools import lru_cache
import hashlib

@lru_cache(maxsize=128)
def cached_analysis(file_hash: str, skill: str) -> str:
    """ç¼“å­˜åˆ†æç»“æœ"""
    client = anthropic.Anthropic()
    response = client.messages.create(
        model="claude-sonnet-4-20250514",
        max_tokens=4096,
        skills=[skill],
        messages=[{"role": "user", "content": f"åˆ†ææ–‡ä»¶ï¼š{file_hash}"}]
    )
    return response.content[0].text

def get_file_hash(file_path: str) -> str:
    """è®¡ç®—æ–‡ä»¶å“ˆå¸Œ"""
    with open(file_path, "rb") as f:
        return hashlib.md5(f.read()).hexdigest()

# ä½¿ç”¨
file_hash = get_file_hash("report.pdf")
result = cached_analysis(file_hash, "pdf")  # é¦–æ¬¡è°ƒç”¨
result = cached_analysis(file_hash, "pdf")  # ä»ç¼“å­˜è¿”å›
```

### 2. è¿æ¥æ± 

```python
from anthropic import Anthropic
import threading

class SkillClientPool:
    """Skill å®¢æˆ·ç«¯è¿æ¥æ± """

    def __init__(self, api_key: str, pool_size: int = 5):
        self.pool = [
            Anthropic(api_key=api_key)
            for _ in range(pool_size)
        ]
        self.lock = threading.Lock()
        self.current = 0

    def get_client(self) -> Anthropic:
        """è·å–å®¢æˆ·ç«¯"""
        with self.lock:
            client = self.pool[self.current]
            self.current = (self.current + 1) % len(self.pool)
            return client

# ä½¿ç”¨
pool = SkillClientPool(api_key="your-key", pool_size=3)
client = pool.get_client()
```

---

## ğŸ’¼ å®æˆ˜æ¡ˆä¾‹

### æ¡ˆä¾‹ï¼šæ‰¹é‡æŠ¥å‘Šç”Ÿæˆç³»ç»Ÿ

```python
import anthropic
import json
from pathlib import Path
from datetime import datetime

class ReportGenerator:
    """æ‰¹é‡æŠ¥å‘Šç”Ÿæˆç³»ç»Ÿ"""

    def __init__(self, api_key: str):
        self.client = anthropic.Anthropic(api_key=api_key)

    def generate_report(self, data_file: str) -> Dict:
        """ç”Ÿæˆå•ä¸ªæŠ¥å‘Š"""
        # 1. åˆ†ææ•°æ®
        skills = smart_skill_selection(data_file)
        analysis = self.client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=4096,
            skills=skills,
            messages=[{
                "role": "user",
                "content": f"åˆ†ææ•°æ®å¹¶ç”ŸæˆæŠ¥å‘Šï¼š{data_file}"
            }]
        )

        # 2. ç”Ÿæˆæ‘˜è¦
        summary = self.client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=1024,
            messages=[{
                "role": "user",
                "content": f"æ€»ç»“ä»¥ä¸‹åˆ†æï¼ˆ100å­—å†…ï¼‰ï¼š\n\n{analysis.content[0].text}"
            }]
        )

        return {
            "file": data_file,
            "analysis": analysis.content[0].text,
            "summary": summary.content[0].text,
            "generated_at": datetime.now().isoformat()
        }

    def batch_generate(self, input_dir: str, output_dir: str):
        """æ‰¹é‡ç”ŸæˆæŠ¥å‘Š"""
        Path(output_dir).mkdir(parents=True, exist_ok=True)

        for data_file in Path(input_dir).glob("*.xlsx"):
            print(f"å¤„ç†ï¼š{data_file.name}...")

            report = self.generate_report(str(data_file))

            # ä¿å­˜æŠ¥å‘Š
            output_file = Path(output_dir) / f"{data_file.stem}_report.json"
            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(report, f, ensure_ascii=False, indent=2)

            print(f"âœ… å®Œæˆï¼š{output_file.name}")

# ä½¿ç”¨
generator = ReportGenerator(api_key="your-key")
generator.batch_generate(
    input_dir="./data",
    output_dir="./reports"
)
```

---

## ğŸ“š å»¶ä¼¸é˜…è¯»

- [åˆ›å»ºè‡ªå®šä¹‰ Skills](creating-custom-skills.md)
- [Skills æœ€ä½³å®è·µ](best-practices.md)
- [æ•…éšœæ’é™¤æŒ‡å—](troubleshooting.md)
- [Skills vs MCP vs Commands](skills-vs-mcp-vs-commands.md)

---

**è¿”å›**: [æŒ‡å—ç›®å½•](README.md) | [ä¸»é¡µ](../README.md)

**æœ€åæ›´æ–°**: 2026-01-24
